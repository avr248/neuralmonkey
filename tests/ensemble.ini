[main]
name=ensemble test
trainer=<trainer>
train_dataset=<train_data>
val_dataset=<val_data>
evaluation=[<bleu>]
output=tests/tmp-test-output
overwrite_output_dir=True
epochs=5
random_seed=1234
logging_period=20
validation_period=30
batch_size=32
save_n_best=4

encoders=[<encoder>]
decoder=<decoder>
runner=<runner>


[bleu]
class=evaluators.bleu.BLEUEvaluator

[train_data]
class=config.utils.dataset_from_files
s_source=tests/data/train.tc.en
s_target=tests/data/train.tc.de
lazy=True

[val_data]
class=config.utils.dataset_from_files
s_source=tests/data/val.tc.en
s_target=tests/data/val.tc.de

[encoder_vocabulary]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=[source]
max_size=5000
save_file=tests/tmp-test-output/encoder_vocabulary.pickle
overwrite=True

[encoder]
class=encoders.sentence_encoder.SentenceEncoder
name=encoder
rnn_size=256
max_input_len=10
embedding_size=200
dropout_keep_p=0.5
attention_type=decoding_function.Attention
data_id=source
vocabulary=<encoder_vocabulary>

[decoder_vocabulary]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=[target]
max_size=5000
save_file=tests/tmp-test-output/decoder_vocabulary.pickle
overwrite=True

[decoder]
class=decoders.decoder.Decoder
name=decoder
encoders=[<encoder>]
rnn_size=256
embedding_size=256
use_attention=True
dropout_keep_p=0.5
data_id=target
max_output_len=10
vocabulary=<decoder_vocabulary>

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
l2_regularization=1.0e-8
decoder=<decoder>

[runner]
class=runners.ensemble_runner.EnsembleRunner
batch_size=16
decoder=<decoder>
